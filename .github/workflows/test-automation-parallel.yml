# ===============================================
# ‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏£‡∏±‡∏ô‡πÄ‡∏ó‡∏™‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
# ===============================================

# ‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô GitHub ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° Run ‡∏ö‡∏ô GitHub
name: ü§ñ Automated Test Results

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏£‡∏±‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà
on:
  # ‡∏£‡∏±‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠ push code ‡πÑ‡∏õ‡∏ó‡∏µ‡πà branch main
  push:
    branches: [ main ]
  # ‡∏£‡∏±‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°‡∏£‡∏±‡∏ô‡πÄ‡∏≠‡∏á‡πÉ‡∏ô GitHub
  workflow_dispatch:

# ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ó‡∏≥
jobs:
  setup-job:
    runs-on: ubuntu-latest
    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4
      - name: üêç Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12.4'
      - name: Install Robot Framework
        run: |
          pip install -r requirements.txt

  test-api:
    needs: setup-job
    runs-on: ubuntu-latest
    steps:
      - name: Copy repo from setup
        uses: actions/checkout@v4
      - name: üß™ Run API Tests
        run: |
          mkdir -p results
          robot --outputdir results --output output.xml --log log.html --report report.html --name "API Tests" TestScript/API/API.robot || true

  test-web:
    needs: setup-job
    runs-on: ubuntu-latest
    steps:
      - name: Copy repo from setup
        uses: actions/checkout@v4
      - name: üß™ Run Web Tests
        run: |
          mkdir -p results
          robot --outputdir results --output output.xml --log log.html --report report.html --name "Web Tests" TestScript/Web/Staging/FlowLogin.robot || true

  # (Optional) ‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å API ‡πÅ‡∏•‡∏∞ Web ‡πÄ‡∏™‡∏£‡πá‡∏à
  summary:
    needs: [test-api, test-web]
    runs-on: ubuntu-latest
    steps:
      - name: ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•/‡∏î‡∏∂‡∏á artifact ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£‡∏Å‡πá‡∏ß‡πà‡∏≤‡πÑ‡∏õ
        run: echo "‡∏™‡∏£‡∏∏‡∏õ‡∏à‡πâ‡∏≤"
      
      # ============================================
      # STEP 3: Generate Test Report
      # ============================================
      - name: üìä Generate Test Summary Report
        if: always()
        run: |
          # ‡∏™‡∏£‡πâ‡∏≤‡∏á Python script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•
          cat > analyze_results.py << 'PYTHON_SCRIPT'
          import xml.etree.ElementTree as ET
          import os
          import json
          
          def analyze_robot_results():
              xml_file = 'results/output.xml'
              
              if not os.path.exists(xml_file):
                  print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö")
                  return
              
              try:
                  tree = ET.parse(xml_file)
                  root = tree.getroot()
                  
                  # ‡∏î‡∏∂‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏´‡∏•‡∏±‡∏Å
                  stats = root.find('.//statistics/total/stat')
                  if stats is None:
                      print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå")
                      return
                  
                  # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Pass/Fail/Skip
                  passed = int(stats.get('pass', 0))
                  failed = int(stats.get('fail', 0))
                  skipped = int(stats.get('skip', 0))
                  total = passed + failed + skipped
                  
                  # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå
                  pass_percentage = (passed / total * 100) if total > 0 else 0
                  fail_percentage = (failed / total * 100) if total > 0 else 0
                  
                  # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÉ‡∏ô Console
                  print("\n" + "="*60)
                  print("üìä WEB TEST EXECUTION SUMMARY")
                  print("="*60)
                  print(f"‚úÖ PASSED:  {passed:3d} tests ({pass_percentage:6.2f}%)")
                  print(f"‚ùå FAILED:  {failed:3d} tests ({fail_percentage:6.2f}%)")
                  if skipped > 0:
                      skip_percentage = (skipped / total * 100)
                      print(f"‚è≠Ô∏è  SKIPPED: {skipped:3d} tests ({skip_percentage:6.2f}%)")
                  print("-"*60)
                  print(f"üìä TOTAL:   {total:3d} tests (100.00%)")
                  print(f"üìà PASS RATE: {pass_percentage:.2f}%")
                  print("="*60)

                  # ‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠ Test
                  passed_details = []
                  failed_details = []
                  passed_tests = []  # ‡πÄ‡∏≠‡∏≤‡πÑ‡∏ß‡πâ‡πÉ‡∏ä‡πâ‡πÇ‡∏ä‡∏ß‡πå row passed ‡πÄ‡∏â‡∏¢‡πÜ

                  for suite in root.findall('.//suite'):
                      for test in suite.findall('.//test'):
                          name = test.get('name', 'Unknown')
                          status = test.find('./status').get('status')
                          if status == 'PASS':
                              passed_details.append({'name': name, 'error': ''})
                              passed_tests.append(name)
                          elif status == 'FAIL':
                              msg_node = test.find('./status')
                              error = msg_node.text.strip() if msg_node is not None and msg_node.text else "No error message"
                              failed_details.append({'name': name, 'error': error})

                  # Debug print
                  print('passed_tests =', passed_tests)
                  print('failed_details =', failed_details)
                  
                  # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå JSON
                  badge_data = {
                      "passed": passed,
                      "failed": failed,
                      "skipped": skipped,
                      "total": total,
                      "pass_rate": round(pass_percentage, 2),
                      "status": "Perfect" if pass_percentage == 100 else "Good" if pass_percentage >= 80 else "Warning"
                  }

                  os.makedirs('results', exist_ok=True)
                  with open('results/test_summary.json', 'w') as f:
                      json.dump(badge_data, f, indent=2)
                  
                  # ‡∏™‡∏£‡πâ‡∏≤‡∏á Markdown ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö GitHub Summary
                  with open('test_summary.md', 'w', encoding='utf-8') as f:
                      # Header
                      if pass_percentage == 100:
                          f.write("# ‚úÖ All Tests Passed!\n\n")
                          status_emoji = "‚úÖ"
                      elif pass_percentage == 0:
                          f.write("# ‚ùå All Tests Failed!\n\n")
                          status_emoji = "‚ùå"
                      else:
                          f.write("# ‚ö†Ô∏è Test Summary\n\n")
                          status_emoji = "‚ö†Ô∏è"
                      
                      f.write("## üìä Summary\n\n")
                      f.write("| Status | Count | Test Case Name | Percentage |\n")
                      f.write("|--------|-------|------------|------------|\n")
                      
                      # Passed (‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠ Passed Tests)
                      if passed > 0:
                          # ‡∏£‡∏ß‡∏°‡∏ä‡∏∑‡πà‡∏≠ test ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÉ‡∏ä‡πâ <br> ‡∏Ñ‡∏±‡πà‡∏ô
                          passed_list = "<br>".join(passed_tests) if passed_tests else "-"
                          f.write(f"| ‚úÖ **Passed** | **{passed}** | {passed_list} | **{pass_percentage:.2f}%** |\n")
                      else:
                          f.write(f"| ‚úÖ **Passed** | **0** | - | **0.00%** |\n")
                      
                      # Fail (‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠ Failed Tests ‡∏û‡∏£‡πâ‡∏≠‡∏° error)
                      if failed > 0:
                          failed_info = []
                          for detail in failed_details:
                              failed_info.append(f"{detail['name']}<br><small>({detail['error']})</small>")
                          failed_names = "<br><br>".join(failed_info)
                          f.write(f"| ‚ùå **Failed** | **{failed}** | {failed_names} | **{fail_percentage:.2f}%** |\n")
                      else:
                          f.write(f"| ‚ùå **Failed** | **0** | - | **0.00%** |\n")

                      # Total (‡πÅ‡∏¢‡∏Å Passed/Failed ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô)
                      all_names_md = ""
                      if passed_details:
                          all_names_md += "<b>‚úÖ Passed</b><br>"
                          for t in passed_details:
                              all_names_md += f"- {t['name']}<br>"
                          all_names_md += "<br>"
                      if failed_details:
                          all_names_md += "<b>‚ùå Failed</b><br>"
                          for t in failed_details:
                              all_names_md += f"- {t['name']}<br>"
                      # ‡∏•‡∏ö <br> ‡∏ó‡πâ‡∏≤‡∏¢‡∏™‡∏∏‡∏î‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
                      if all_names_md.endswith("<br>"):
                          all_names_md = all_names_md[:-4]
                      if not all_names_md.strip():
                          all_names_md = "-"
                      f.write(f"| üìä **Total** | **{total}** | {all_names_md} | **100.00%** |\n\n")
                      
                  print("\n‚úÖ Summary files created successfully!")
                  
              except Exception as e:
                  print(f"‚ùå Error analyzing results: {str(e)}")
                  import traceback
                  traceback.print_exc()
          
          if __name__ == "__main__":
              analyze_robot_results()
          PYTHON_SCRIPT
          
          # ‡∏£‡∏±‡∏ô script ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•
          python analyze_results.py
      
      - name: üìù Update GitHub Job Summary
        if: always()
        run: |
          # ‡πÄ‡∏û‡∏¥‡πà‡∏° Summary ‡πÉ‡∏ô GitHub
          if [ -f "test_summary.md" ]; then
            cat test_summary.md >> $GITHUB_STEP_SUMMARY
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "---" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### üìå Test Information" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "- **Branch:** ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Runner:** ${{ runner.os }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Triggered by:** @${{ github.actor }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Workflow:** ${{ github.workflow }}" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ö†Ô∏è No test summary available" >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Set current date and time
        id: set-datetime
        run: echo "datetime=$(TZ='Asia/Bangkok' date +'%Y-%m-%d_%H-%M-%S')" >> $GITHUB_OUTPUT

      - name: üìÅ Upload Test Results Artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: Robot-Test-Results-${{ steps.set-datetime.outputs.datetime }}
          path: results/
          retention-days: 30
                