# ===============================================
# Parallel Test Automation Pipeline
# ===============================================

name: 🤖 Automated Test Results

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

jobs:
  # ============================================
  # JOB 1: Web Testing
  # ============================================
  test-web:
    runs-on: ubuntu-latest
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4
      
      - name: 📥 Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12.4'
      
      - name: 📥 Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: 🧪 Run Web Tests
        run: |
          mkdir -p results/web
          robot \
            --variable BROWSER:headlesschrome \
            --outputdir results/web \
            --output output.xml \
            --log log.html \
            --report report.html \
            --name "Web Tests" \
            TestScript/Web/Staging/FlowLogin.robot || true
      
      - name: 📊 Generate Web Summary
        if: always()
        run: |
          cat > analyze_web.py << 'EOF'
          import xml.etree.ElementTree as ET
          import json
          
          tree = ET.parse('results/web/output.xml')
          root = tree.getroot()
          stats = root.find('.//statistics/total/stat')
          
          passed = int(stats.get('pass', 0))
          failed = int(stats.get('fail', 0))
          total = passed + failed
          
          summary = {
              "type": "web",
              "passed": passed,
              "failed": failed,
              "total": total,
              "pass_rate": round((passed/total*100), 2) if total > 0 else 0
          }
          
          with open('results/web/summary.json', 'w') as f:
              json.dump(summary, f, indent=2)
          
          print(f"✅ Web Tests: {passed}/{total} passed ({summary['pass_rate']}%)")
          EOF
          
          python analyze_web.py
      
      - name: 📤 Upload Web Results
        uses: actions/upload-artifact@v4
        with:
          name: web-results
          path: results/web/

  # ============================================
  # JOB 2: API Testing
  # ============================================
  test-api:
    runs-on: ubuntu-latest
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4
      
      - name: 📥 Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12.4'
      
      - name: 📥 Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: 🧪 Run API Tests
        run: |
          mkdir -p results/api
          robot \
            --outputdir results/api \
            --output output.xml \
            --log log.html \
            --report report.html \
            --name "API Tests" \
            TestScript/API/API.robot || true
      
      - name: 📊 Generate API Summary
        if: always()
        run: |
          cat > analyze_api.py << 'EOF'
          import xml.etree.ElementTree as ET
          import json
          
          tree = ET.parse('results/api/output.xml')
          root = tree.getroot()
          stats = root.find('.//statistics/total/stat')
          
          passed = int(stats.get('pass', 0))
          failed = int(stats.get('fail', 0))
          total = passed + failed
          
          summary = {
              "type": "api",
              "passed": passed,
              "failed": failed,
              "total": total,
              "pass_rate": round((passed/total*100), 2) if total > 0 else 0
          }
          
          with open('results/api/summary.json', 'w') as f:
              json.dump(summary, f, indent=2)
          
          print(f"✅ API Tests: {passed}/{total} passed ({summary['pass_rate']}%)")
          EOF
          
          python analyze_api.py
      
      - name: 📤 Upload API Results
        uses: actions/upload-artifact@v4
        with:
          name: api-results
          path: results/api/

  # ============================================
  # JOB 3: Combined Summary Report
  # ============================================
  summary:
    needs: [test-web, test-api]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: 📥 Download Web Results
        uses: actions/download-artifact@v4
        with:
          name: web-results
          path: web-results/
      
      - name: 📥 Download API Results
        uses: actions/download-artifact@v4
        with:
          name: api-results
          path: api-results/
      
      - name: 📊 Generate Combined Report
        run: |
          cat > generate_report.py << 'EOF'
          import json
          import xml.etree.ElementTree as ET
          import os
          from datetime import datetime
          
          def parse_xml(xml_path, test_type):
              """Parse Robot Framework XML and extract test details"""
              if not os.path.exists(xml_path):
                  return None
                  
              tree = ET.parse(xml_path)
              root = tree.getroot()
              
              stats = root.find('.//statistics/total/stat')
              passed = int(stats.get('pass', 0))
              failed = int(stats.get('fail', 0))
              total = passed + failed
              
              # Extract test details
              passed_tests = []
              failed_tests = []
              
              for suite in root.findall('.//suite'):
                  for test in suite.findall('.//test'):
                      name = test.get('name', 'Unknown')
                      status = test.find('./status').get('status')
                      
                      if status == 'PASS':
                          passed_tests.append(name)
                      elif status == 'FAIL':
                          msg_node = test.find('./status')
                          error_msg = ""
                          if msg_node is not None and msg_node.text:
                              # Clean error message
                              error_msg = msg_node.text.strip().replace('\n', ' ')[:100]
                          failed_tests.append({
                              'name': name,
                              'error': error_msg
                          })
              
              return {
                  'passed': passed,
                  'failed': failed,
                  'total': total,
                  'pass_rate': round((passed/total*100), 2) if total > 0 else 0,
                  'passed_tests': passed_tests,
                  'failed_tests': failed_tests
              }
          
          # Parse both test results
          web_results = parse_xml('web-results/output.xml', 'Web')
          api_results = parse_xml('api-results/output.xml', 'API')
          
          # Calculate combined statistics
          total_passed = (web_results['passed'] if web_results else 0) + (api_results['passed'] if api_results else 0)
          total_failed = (web_results['failed'] if web_results else 0) + (api_results['failed'] if api_results else 0)
          total_tests = total_passed + total_failed
          overall_pass_rate = round((total_passed/total_tests*100), 2) if total_tests > 0 else 0
          
          # Generate Markdown report
          with open('test_summary.md', 'w', encoding='utf-8') as f:
              # Header with overall status
              if overall_pass_rate == 100:
                  f.write("# ✅ All Tests Passed!\n\n")
              elif overall_pass_rate >= 80:
                  f.write("# 🎯 Tests Mostly Passed\n\n")
              elif overall_pass_rate >= 50:
                  f.write("# ⚠️ Some Tests Failed\n\n")
              else:
                  f.write("# ❌ Many Tests Failed\n\n")
              
              # Overall Summary Box
              f.write("## 📊 Overall Summary\n\n")
              f.write("```\n")
              f.write(f"Total Pass Rate: {overall_pass_rate}% ({total_passed}/{total_tests})\n")
              f.write(f"✅ Passed: {total_passed} tests\n")
              f.write(f"❌ Failed: {total_failed} tests\n")
              f.write("```\n\n")
              
              # Test Breakdown by Type
              f.write("## 📈 Test Breakdown by Type\n\n")
              f.write("| Test Type | Passed | Failed | Total | Pass Rate |\n")
              f.write("|:----------|:------:|:------:|:-----:|----------:|\n")
              
              # Web Tests Row
              if web_results:
                  f.write(f"| **Web Tests** | {web_results['passed']} | {web_results['failed']} | {web_results['total']} | **{web_results['pass_rate']}%** |\n")
              else:
                  f.write("| **Web Tests** | - | - | - | **N/A** |\n")
              
              # API Tests Row
              if api_results:
                  f.write(f"| **API Tests** | {api_results['passed']} | {api_results['failed']} | {api_results['total']} | **{api_results['pass_rate']}%** |\n")
              else:
                  f.write("| **API Tests** | - | - | - | **N/A** |\n")
              
              # Total Row
              f.write(f"| **TOTAL** | **{total_passed}** | **{total_failed}** | **{total_tests}** | **{overall_pass_rate}%** |\n\n")
              
              # Test Cases Details - Web Tests
              if web_results and (web_results['passed_tests'] or web_results['failed_tests']):
                  f.write("### 🌐 Web Test Cases\n\n")
                  
                  if web_results['passed_tests']:
                      f.write("#### ✅ Passed Tests\n")
                      f.write("```\n")
                      for i, test in enumerate(web_results['passed_tests'], 1):
                          f.write(f"{i}. {test}\n")
                      f.write("```\n\n")
                  
                  if web_results['failed_tests']:
                      f.write("#### ❌ Failed Tests\n")
                      f.write("```\n")
                      for i, test in enumerate(web_results['failed_tests'], 1):
                          f.write(f"{i}. {test['name']}\n")
                          if test['error']:
                              f.write(f"   Error: {test['error']}\n")
                      f.write("```\n\n")
              
              # Test Cases Details - API Tests
              if api_results and (api_results['passed_tests'] or api_results['failed_tests']):
                  f.write("### 🔌 API Test Cases\n\n")
                  
                  if api_results['passed_tests']:
                      f.write("#### ✅ Passed Tests\n")
                      f.write("```\n")
                      for i, test in enumerate(api_results['passed_tests'], 1):
                          f.write(f"{i}. {test}\n")
                      f.write("```\n\n")
                  
                  if api_results['failed_tests']:
                      f.write("#### ❌ Failed Tests\n")
                      f.write("```\n")
                      for i, test in enumerate(api_results['failed_tests'], 1):
                          f.write(f"{i}. {test['name']}\n")
                          if test['error']:
                              f.write(f"   Error: {test['error']}\n")
                      f.write("```\n\n")
              
              # Failed Tests Summary (if any)
              all_failed = []
              if web_results:
                  all_failed.extend([{'type': 'Web', **t} for t in web_results['failed_tests']])
              if api_results:
                  all_failed.extend([{'type': 'API', **t} for t in api_results['failed_tests']])
              
              if all_failed:
                  f.write("## 🔍 Failed Tests Summary\n\n")
                  f.write("| # | Type | Test Name | Error |\n")
                  f.write("|:--|:-----|:----------|:------|\n")
                  for i, test in enumerate(all_failed, 1):
                      error = test['error'][:60] + "..." if len(test['error']) > 60 else test['error']
                      error = error.replace('|', '\\|').replace('\n', ' ')
                      f.write(f"| {i} | {test['type']} | {test['name']} | {error} |\n")
                  f.write("\n")
              
              # Execution Details
              f.write("## 📝 Execution Details\n\n")
              f.write("```yaml\n")
              f.write(f"Execution Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}\n")
              f.write(f"Branch: ${{{{ github.ref_name }}}}\n")
              f.write(f"Commit: ${{{{ github.sha }}}}\n")
              f.write(f"Triggered by: @${{{{ github.actor }}}}\n")
              f.write(f"Workflow: ${{{{ github.workflow }}}}\n")
              f.write("```\n")
              
              # Quick Copy Section
              f.write("\n---\n\n")
              f.write("### 📋 Quick Summary (Copy-Paste Ready)\n\n")
              f.write("```\n")
              f.write("TEST EXECUTION SUMMARY\n")
              f.write("=" * 50 + "\n")
              f.write(f"Overall Pass Rate: {overall_pass_rate}% ({total_passed}/{total_tests})\n")
              f.write("\n")
              
              if web_results:
                  f.write(f"Web Tests: {web_results['pass_rate']}% ({web_results['passed']}/{web_results['total']})\n")
                  if web_results['passed_tests']:
                      f.write("  ✅ Passed:\n")
                      for test in web_results['passed_tests']:
                          f.write(f"     - {test}\n")
                  if web_results['failed_tests']:
                      f.write("  ❌ Failed:\n")
                      for test in web_results['failed_tests']:
                          f.write(f"     - {test['name']}\n")
              
              if api_results:
                  f.write(f"\nAPI Tests: {api_results['pass_rate']}% ({api_results['passed']}/{api_results['total']})\n")
                  if api_results['passed_tests']:
                      f.write("  ✅ Passed:\n")
                      for test in api_results['passed_tests']:
                          f.write(f"     - {test}\n")
                  if api_results['failed_tests']:
                      f.write("  ❌ Failed:\n")
                      for test in api_results['failed_tests']:
                          f.write(f"     - {test['name']}\n")
              
              f.write("=" * 50 + "\n")
              f.write("```\n")
          
          # Console output
          print("\n" + "="*60)
          print("📊 TEST EXECUTION SUMMARY")
          print("="*60)
          print(f"Overall Pass Rate: {overall_pass_rate}% ({total_passed}/{total_tests})")
          print("-"*60)
          
          if web_results:
              print(f"\n🌐 Web Tests: {web_results['pass_rate']}% ({web_results['passed']}/{web_results['total']})")
              if web_results['passed_tests']:
                  print("  ✅ Passed:")
                  for test in web_results['passed_tests']:
                      print(f"     - {test}")
              if web_results['failed_tests']:
                  print("  ❌ Failed:")
                  for test in web_results['failed_tests']:
                      print(f"     - {test['name']}")
          
          if api_results:
              print(f"\n🔌 API Tests: {api_results['pass_rate']}% ({api_results['passed']}/{api_results['total']})")
              if api_results['passed_tests']:
                  print("  ✅ Passed:")
                  for test in api_results['passed_tests']:
                      print(f"     - {test}")
              if api_results['failed_tests']:
                  print("  ❌ Failed:")
                  for test in api_results['failed_tests']:
                      print(f"     - {test['name']}")
          
          print("="*60)
          EOF
          
          python generate_report.py
      
      - name: 📝 Update GitHub Job Summary
        if: always()
        run: |
          if [ -f "test_summary.md" ]; then
            cat test_summary.md >> $GITHUB_STEP_SUMMARY
          else
            echo "⚠️ No test summary available" >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: 🗓️ Set current date and time
        id: datetime
        run: echo "datetime=$(TZ='Asia/Bangkok' date +'%Y-%m-%d_%H-%M-%S')" >> $GITHUB_OUTPUT
      
      - name: 📦 Create Combined Artifact
        if: always()
        run: |
          mkdir -p combined-results
          cp -r web-results/* combined-results/web/ 2>/dev/null || true
          cp -r api-results/* combined-results/api/ 2>/dev/null || true
          cp test_summary.md combined-results/ 2>/dev/null || true
      
      - name: 📤 Upload Combined Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: Test-Results-${{ steps.datetime.outputs.datetime }}
          path: combined-results/
          retention-days: 30
      
      # - name: 🚨 Check Test Status
      #   if: always()
      #   run: |
      #     # Parse results and fail if tests failed
      #     python << 'EOF'
      #     import json
      #     import sys
      #     import os
          
      #     failed_count = 0
          
      #     # Check web results
      #     if os.path.exists('web-results/summary.json'):
      #         with open('web-results/summary.json') as f:
      #             web = json.load(f)
      #             failed_count += web.get('failed', 0)
          
      #     # Check API results  
      #     if os.path.exists('api-results/summary.json'):
      #         with open('api-results/summary.json') as f:
      #             api = json.load(f)
      #             failed_count += api.get('failed', 0)
          
      #     if failed_count > 0:
      #         print(f"❌ {failed_count} tests failed!")
      #         sys.exit(1)
      #     else:
      #         print("✅ All tests passed!")
      #         sys.exit(0)
      #     EOF